#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()
DB_URL = os.getenv('DATABASE_URL')

def analyze_database():
    """Analizuje bazƒô danych pod kƒÖtem wydajno≈õci"""
    conn = psycopg2.connect(DB_URL)
    cur = conn.cursor()

    print('üîç ANALIZA WYDAJNO≈öCI BAZY DANYCH')
    print('=' * 50)

    # Sprawd≈∫ istniejƒÖce indeksy
    print('\nüìä ISTNIEJƒÑCE INDEKSY:')
    cur.execute('''
        SELECT 
            schemaname, tablename, indexname, indexdef
        FROM pg_indexes 
        WHERE schemaname = 'public'
        ORDER BY tablename, indexname;
    ''')

    for row in cur.fetchall():
        print(f'  {row[1]}.{row[2]}: {row[3]}')

    # Rozmiary tabel
    print('\nüìè ROZMIARY TABEL:')
    cur.execute('''
        SELECT 
            schemaname, tablename, 
            pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
            pg_total_relation_size(schemaname||'.'||tablename) as size_bytes
        FROM pg_tables 
        WHERE schemaname = 'public'
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
    ''')

    for row in cur.fetchall():
        print(f'  {row[1]}: {row[2]}')

    # Statystyki tabel
    print('\nüìà LICZBA REKORD√ìW:')
    tables = ['zawodnicy', 'wyniki', 'checkpoints', 'kluby']
    for table in tables:
        try:
            cur.execute(f'SELECT COUNT(*) FROM {table}')
            count = cur.fetchone()[0]
            print(f'  {table}: {count:,} rekord√≥w')
        except:
            print(f'  {table}: tabela nie istnieje')

    # Sprawd≈∫ najczƒô≈õciej u≈ºywane zapytania (analysis)
    print('\nüîé ANALIZA POTENCJALNYCH PROBLEM√ìW:')
    
    # BrakujƒÖce indeksy na czƒôsto u≈ºywanych kolumnach
    missing_indexes = []
    
    # Sprawd≈∫ czy sƒÖ indeksy na kluczowych kolumnach
    important_columns = [
        ('zawodnicy', 'kategoria'),
        ('zawodnicy', 'plec'),
        ('zawodnicy', 'klub'),
        ('zawodnicy', 'qr_code'),
        ('zawodnicy', 'checked_in'),
        ('wyniki', 'status'),
        ('wyniki', 'czas_przejazdu_s'),
        ('checkpoints', 'checkpoint_name'),
        ('checkpoints', 'timestamp'),
        ('checkpoints', 'device_id'),
        ('checkpoints', 'nr_startowy')
    ]
    
    for table, column in important_columns:
        cur.execute('''
            SELECT COUNT(*) FROM pg_indexes 
            WHERE tablename = %s 
            AND indexdef LIKE %s
        ''', (table, f'%{column}%'))
        
        index_count = cur.fetchone()[0]
        if index_count == 0:
            missing_indexes.append(f'{table}.{column}')
    
    if missing_indexes:
        print('\n‚ùå BRAKUJƒÑCE INDEKSY:')
        for missing in missing_indexes:
            print(f'  - {missing}')
    else:
        print('\n‚úÖ Wszystkie wa≈ºne kolumny majƒÖ indeksy')

    # Sprawd≈∫ duplikaty w checkpoints
    print('\nüîÑ SPRAWDZANIE DUPLIKAT√ìW:')
    cur.execute('''
        SELECT nr_startowy, checkpoint_name, COUNT(*)
        FROM checkpoints
        GROUP BY nr_startowy, checkpoint_name
        HAVING COUNT(*) > 1
        ORDER BY COUNT(*) DESC
        LIMIT 10
    ''')
    
    duplicates = cur.fetchall()
    if duplicates:
        print('  ‚ùå Znalezione duplikaty w checkpoints:')
        for nr, checkpoint, count in duplicates:
            print(f'    Nr {nr}, {checkpoint}: {count} razy')
    else:
        print('  ‚úÖ Brak duplikat√≥w w checkpoints')

    # Sprawd≈∫ wolne zapytania (symulacja)
    print('\n‚è±Ô∏è POTENCJALNE PROBLEMY WYDAJNO≈öCI:')
    
    # Sprawd≈∫ zapytania bez WHERE
    issues = []
    
    # Du≈ºe JOINy bez indeks√≥w
    cur.execute('''
        SELECT COUNT(*)
        FROM zawodnicy z
        LEFT JOIN wyniki w ON z.nr_startowy = w.nr_startowy
        LEFT JOIN checkpoints c ON z.nr_startowy = c.nr_startowy
    ''')
    
    total_joins = cur.fetchone()[0]
    if total_joins > 1000:
        issues.append(f'Du≈ºe JOIN operations ({total_joins:,} rekord√≥w)')

    # Sprawd≈∫ fragmentacjƒô checkpoints
    cur.execute('SELECT COUNT(*) FROM checkpoints WHERE timestamp < NOW() - INTERVAL \'30 days\'')
    old_checkpoints = cur.fetchone()[0]
    if old_checkpoints > 1000:
        issues.append(f'Stare checkpoints do archiwizacji: {old_checkpoints:,}')

    if issues:
        for issue in issues:
            print(f'  ‚ö†Ô∏è  {issue}')
    else:
        print('  ‚úÖ Brak oczywistych problem√≥w wydajno≈õci')

    cur.close()
    conn.close()

if __name__ == '__main__':
    analyze_database() 